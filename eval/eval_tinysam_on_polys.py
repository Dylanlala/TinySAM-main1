#!/usr/bin/env python3
import os
import sys
import time
import json
from pathlib import Path
from typing import List, Optional, Tuple

import cv2
import numpy as np
import torch

# Ensure project root on sys.path for local 'tinysam' imports
PROJECT_ROOT = Path(__file__).resolve().parents[1]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from tinysam.build_sam import sam_model_registry
from tinysam.predictor import SamPredictor

try:
    from ultralytics import YOLO  # optional
except Exception:
    YOLO = None


def is_image_file(filename: str) -> bool:
    exts = [".jpg", ".jpeg", ".png", ".bmp", ".tif", ".tiff"]
    return any(filename.lower().endswith(ext) for ext in exts)


def try_read_image(path: Path) -> Optional[np.ndarray]:
    try:
        img = cv2.imread(str(path))
        if img is None:
            return None
        return img
    except Exception:
        return None


def find_image_and_mask_pairs(images_root: Path, ann_root: Path) -> List[Tuple[Path, Optional[Path]]]:
    """æŸ¥æ‰¾å›¾åƒå’Œæ ‡æ³¨æ–‡ä»¶å¯¹ï¼Œæ”¯æŒYOLOæ ¼å¼çš„txtæ–‡ä»¶"""
    pairs: List[Tuple[Path, Optional[Path]]] = []
    for dirpath, _, filenames in os.walk(images_root):
        for fname in filenames:
            if not is_image_file(fname):
                continue
            img_path = Path(dirpath) / fname
            # mirror subdir under ann_root
            rel = img_path.relative_to(images_root)
            mask_dir = ann_root / rel.parent
            mask_base = rel.stem
            
            # é¦–å…ˆå°è¯•æŸ¥æ‰¾å›¾åƒæ ¼å¼çš„æ©ç æ–‡ä»¶
            gt_mask_path: Optional[Path] = None
            for suffix in [".png", ".jpg", ".tif", ".tiff", ".bmp"]:
                candidate = mask_dir / f"{mask_base}{suffix}"
                if candidate.exists():
                    gt_mask_path = candidate
                    break
                candidate2 = mask_dir / f"{mask_base}_mask{suffix}"
                if candidate2.exists():
                    gt_mask_path = candidate2
                    break
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å›¾åƒæ ¼å¼çš„æ©ç ï¼Œå°è¯•æŸ¥æ‰¾YOLOæ ¼å¼çš„txtæ–‡ä»¶
            if gt_mask_path is None:
                txt_candidate = mask_dir / f"{mask_base}.txt"
                if txt_candidate.exists():
                    gt_mask_path = txt_candidate
            
            pairs.append((img_path, gt_mask_path))
    return pairs


def create_mask_from_yolo_txt(txt_path: Path, img_shape: Tuple[int, int, int]) -> Optional[np.ndarray]:
    """ä»è‡ªå®šä¹‰è¾¹ç•Œæ¡†æ ¼å¼çš„txtæ–‡ä»¶åˆ›å»ºæ©ç """
    try:
        with open(txt_path, 'r') as f:
            lines = f.readlines()
        
        if len(lines) < 2:
            return None
        
        h, w = img_shape[:2]
        mask = np.zeros((h, w), dtype=np.uint8)
        
        # ç¬¬ä¸€è¡Œæ˜¯ç±»åˆ«IDï¼Œç¬¬äºŒè¡Œæ˜¯è¾¹ç•Œæ¡†åæ ‡
        if len(lines) >= 2:
            try:
                # è§£æè¾¹ç•Œæ¡†åæ ‡: x1 y1 x2 y2
                coords = lines[1].strip().split()
                if len(coords) >= 4:
                    x1 = max(0, int(float(coords[0])))
                    y1 = max(0, int(float(coords[1])))
                    x2 = min(w, int(float(coords[2])))
                    y2 = min(h, int(float(coords[3])))
                    
                    # ç¡®ä¿åæ ‡æœ‰æ•ˆ
                    if x1 < x2 and y1 < y2:
                        # åœ¨æ©ç ä¸Šç»˜åˆ¶çŸ©å½¢åŒºåŸŸ
                        mask[y1:y2, x1:x2] = 255
                        print(f"    Created mask for bbox: ({x1}, {y1}) to ({x2}, {y2})")
                    else:
                        print(f"    Invalid bbox coordinates: ({x1}, {y1}) to ({x2}, {y2})")
                else:
                    print(f"    Insufficient coordinates in line: {lines[1].strip()}")
            except (ValueError, IndexError) as e:
                print(f"    Error parsing coordinates: {e}")
                return None
        
        return mask
    except Exception as e:
        print(f"Error reading annotation {txt_path}: {e}")
        return None


class TinySAMEvaluator:
    def __init__(
        self,
        sam_weights: str,
        yolo_weights: Optional[str] = None,
        device: Optional[str] = None,
        yolo_conf: float = 0.25,
        yolo_iou: float = 0.45,
    ) -> None:
        self.device = torch.device(device or ("cuda" if torch.cuda.is_available() else "cpu"))
        self._load_sam(sam_weights)
        self._load_yolo(yolo_weights, yolo_conf, yolo_iou)

    def _load_sam(self, sam_weights: str) -> None:
        self.sam = sam_model_registry["vit_t"](checkpoint=sam_weights).to(self.device)
        self.sam_predictor = SamPredictor(self.sam)

    def _load_yolo(self, yolo_weights: Optional[str], conf: float, iou: float) -> None:
        self.yolo = None
        self.yolo_conf = conf
        self.yolo_iou = iou
        if yolo_weights:
            if YOLO is None:
                raise RuntimeError("ultralytics not available but yolo_weights was provided")
            self.yolo = YOLO(yolo_weights)

    @torch.no_grad()
    def predict_mask_with_sam(self, image_bgr: np.ndarray) -> Tuple[np.ndarray, int]:
        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
        self.sam_predictor.set_image(image_rgb)

        combined_mask = np.zeros(image_bgr.shape[:2], dtype=np.uint8)
        detection_count = 0

        if self.yolo is not None:
            yolo_results = self.yolo(image_rgb, conf=self.yolo_conf, iou=self.yolo_iou)
            for box in yolo_results[0].boxes:
                x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
                cx, cy = (x1 + x2) // 2, (y1 + y2) // 2
                masks, _, _ = self.sam_predictor.predict(
                    point_coords=np.array([[cx, cy]]),
                    point_labels=np.array([1]),
                    box=np.array([x1, y1, x2, y2])
                )
                if len(masks) > 0:
                    combined_mask = np.logical_or(combined_mask, masks[0]).astype(np.uint8)
                    detection_count += 1
        else:
            # Fallback: sparse grid prompts across the image center region
            h, w = image_bgr.shape[:2]
            grid_x = np.linspace(w * 0.25, w * 0.75, num=3, dtype=int)
            grid_y = np.linspace(h * 0.25, h * 0.75, num=3, dtype=int)
            points = np.array([[x, y] for y in grid_y for x in grid_x])
            labels = np.ones(len(points), dtype=np.int32)
            masks, _, _ = self.sam_predictor.predict(point_coords=points, point_labels=labels)
            if len(masks) > 0:
                combined_mask = np.max(masks.astype(np.uint8), axis=0)
                detection_count = len(points)

        return combined_mask, detection_count

    def _compute_metrics_numpy(self, gt_bin: np.ndarray, pr_bin: np.ndarray) -> dict:
        """ä½¿ç”¨æ¯è‚‰çº§è¿é€šåŸŸåŒ¹é…æ–¹æ³•è®¡ç®—æ€§èƒ½æŒ‡æ ‡ï¼Œå‚è€ƒè®­ç»ƒè„šæœ¬çš„é€»è¾‘"""
        try:
            from skimage.measure import label, regionprops
            print(f"    Using connected component analysis...")
        except ImportError:
            print("Warning: skimage not available, falling back to pixel-level metrics")
            return self._compute_metrics_pixel_level(gt_bin, pr_bin)
        
        # ä½¿ç”¨è¿é€šåŸŸæ ‡è®°
        gt_label = label(gt_bin)
        pr_label = label(pr_bin)
        
        # è·å–è¿é€šåŸŸå±æ€§
        gt_regions = regionprops(gt_label)
        pr_regions = regionprops(pr_label)
        
        print(f"    GT regions: {len(gt_regions)}, Pred regions: {len(pr_regions)}")
        
        if len(gt_regions) == 0 and len(pr_regions) == 0:
            print("    No regions found, returning zero metrics")
            return {"dice": 0.0, "iou": 0.0, "precision": 0.0, "recall": 0.0, "tp": 0, "fp": 0, "fn": 0, "tn": 0}
        
        # æ¯è‚‰çº§æŒ‡æ ‡ï¼šé€æ ·æœ¬æŒ‰è¿é€šåŸŸåŒ¹é…
        image_dice, image_iou, image_tp, image_fp, image_fn = [], [], 0, 0, 0
        
        # å¯¹æ¯ä¸ªçœŸå®æ¯è‚‰åŒºåŸŸï¼Œæ‰¾åˆ°æœ€ä½³åŒ¹é…çš„é¢„æµ‹åŒºåŸŸ
        for tr in gt_regions:
            true_mask_i = (gt_label == tr.label)
            best_iou = 0.0
            best_dice = 0.0
            ts = true_mask_i.sum()
            
            for pr in pr_regions:
                pred_mask_i = (pr_label == pr.label)
                ps = pred_mask_i.sum()
                
                if ps == 0 or ts == 0:
                    continue
                
                # è®¡ç®—äº¤é›†å’Œå¹¶é›†
                inter = np.logical_and(true_mask_i, pred_mask_i).sum()
                union = np.logical_or(true_mask_i, pred_mask_i).sum()
                
                iou = inter / union if union > 0 else 0.0
                dice = (2 * inter) / (ts + ps) if (ts + ps) > 0 else 0.0
                
                if iou > best_iou:
                    best_iou = iou
                    best_dice = dice
            
            # åªæœ‰IoU > 0.5çš„åŒ¹é…æ‰è®¡å…¥ç»Ÿè®¡ï¼ˆå‚è€ƒè®­ç»ƒè„šæœ¬ï¼‰
            if best_iou > 0.5:
                image_dice.append(best_dice)
                image_iou.append(best_iou)
                image_tp += 1
                print(f"    Matched region: IoU={best_iou:.4f}, Dice={best_dice:.4f}")
            else:
                image_fn += 1
                print(f"    Unmatched region: IoU={best_iou:.4f}")
        
        # è®¡ç®—å‡é˜³æ€§ï¼ˆå¤šä½™çš„é¢„æµ‹åŒºåŸŸï¼‰
        image_fp = max(0, len(pr_regions) - image_tp)
        
        # è®¡ç®—ç²¾ç¡®ç‡å’Œå¬å›ç‡
        precision = image_tp / (image_tp + image_fp) if (image_tp + image_fp) > 0 else 0.0
        recall = image_tp / (image_tp + image_fn) if (image_tp + image_fn) > 0 else 0.0
        
        # è®¡ç®—å¹³å‡Diceå’ŒIoU
        avg_dice = float(np.mean(image_dice)) if image_dice else 0.0
        avg_iou = float(np.mean(image_iou)) if image_iou else 0.0
        
        # è®¡ç®—F1åˆ†æ•°
        f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0
        
        print(f"    Final metrics: TP={image_tp}, FP={image_fp}, FN={image_fn}")
        print(f"    Precision={precision:.4f}, Recall={recall:.4f}, F1={f1:.4f}")
        
        return {
            "dice": avg_dice,
            "iou": avg_iou,
            "precision": float(precision),
            "recall": float(recall),
            "f1": float(f1),
            "tp": image_tp,
            "fp": image_fp,
            "fn": image_fn,
            "gt_regions": len(gt_regions),
            "pred_regions": len(pr_regions)
        }
    
    def _compute_metrics_pixel_level(self, gt_bin: np.ndarray, pr_bin: np.ndarray) -> dict:
        """åƒç´ çº§æ€§èƒ½æŒ‡æ ‡è®¡ç®—ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰"""
        gt_flat = gt_bin.astype(np.uint8).flatten()
        pr_flat = pr_bin.astype(np.uint8).flatten()
        
        if gt_flat.size == 0 or pr_flat.size == 0:
            return {"dice": 0.0, "iou": 0.0, "precision": 0.0, "recall": 0.0, "tp": 0, "fp": 0, "fn": 0, "tn": 0}
        
        tp = int(np.sum((gt_flat == 1) & (pr_flat == 1)))
        fp = int(np.sum((gt_flat == 0) & (pr_flat == 1)))
        fn = int(np.sum((gt_flat == 1) & (pr_flat == 0)))
        tn = int(np.sum((gt_flat == 0) & (pr_flat == 0)))
        
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0
        dice = (2 * tp) / (2 * tp + fp + fn) if (2 * tp + fp + fn) > 0 else 0.0
        iou = tp / (tp + fp + fn) if (tp + fp + fn) > 0 else 0.0
        
        return {
            "dice": float(dice),
            "iou": float(iou),
            "precision": float(precision),
            "recall": float(recall),
            "tp": tp,
            "fp": fp,
            "fn": fn,
            "tn": tn
        }

    def _read_boxes_from_txt(self, txt_path: Path, img_shape: Tuple[int, int, int]) -> Tuple[List[Tuple[int, int, int, int]], bool]:
        """ä»txtæ–‡ä»¶è¯»å–è¾¹ç•Œæ¡†åæ ‡ï¼Œå¹¶è¯†åˆ«é˜´æ€§æ ·æœ¬ï¼ˆé¦–è¡Œ0è¡¨ç¤ºæ— æ¯è‚‰ï¼‰ã€‚

        è¿”å›: (boxes_list, is_negative)
        """
        try:
            with open(txt_path, 'r') as f:
                raw_lines = [ln.strip() for ln in f.readlines() if ln.strip()]
            
            if not raw_lines:
                return [], False
            
            # é¦–è¡Œå¯èƒ½æ˜¯æ ‡å¿—ä½ï¼š0=é˜´æ€§ï¼Œ1=é˜³æ€§
            first = raw_lines[0]
            is_negative = first == '0'
            # å¦‚æœé¦–è¡Œæ˜¯0æˆ–1ï¼Œåˆ™å‰©ä½™è¡Œæ‰æ˜¯æ¡†ï¼›å¦åˆ™æ‰€æœ‰è¡Œä¸ºæ¡†
            lines = raw_lines[1:] if first in ('0', '1') else raw_lines
            
            boxes: List[Tuple[int, int, int, int]] = []
            for line in lines:
                parts = line.split()
                if len(parts) >= 4:
                    # è§£æè¾¹ç•Œæ¡†åæ ‡: x1 y1 x2 y2
                    x1 = max(0, int(float(parts[0])))
                    y1 = max(0, int(float(parts[1])))
                    x2 = min(img_shape[1], int(float(parts[2])))
                    y2 = min(img_shape[0], int(float(parts[3])))
                    if x1 < x2 and y1 < y2:
                        boxes.append((x1, y1, x2, y2))
            return boxes, is_negative
        except Exception as e:
            print(f"Error reading boxes from {txt_path}: {e}")
            return [], False
    
    def predict_mask_with_boxes(self, image_bgr: np.ndarray, boxes_list: List[Tuple[int, int, int, int]]) -> Tuple[np.ndarray, int]:
        """ä½¿ç”¨è¾¹ç•Œæ¡†æç¤ºè¿›è¡ŒSAMé¢„æµ‹ï¼ˆå‚è€ƒè®­ç»ƒè„šæœ¬ï¼‰"""
        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
        self.sam_predictor.set_image(image_rgb)
        
        combined_mask = np.zeros(image_bgr.shape[:2], dtype=np.uint8)
        detection_count = 0
        
        for x1, y1, x2, y2 in boxes_list:
            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2
            
            masks, _, _ = self.sam_predictor.predict(
                point_coords=np.array([[cx, cy]]),
                point_labels=np.array([1]),
                box=np.array([x1, y1, x2, y2])
            )
            
            if len(masks) > 0:
                combined_mask = np.logical_or(combined_mask, masks[0]).astype(np.uint8)
                detection_count += 1
        
        return combined_mask, detection_count

    def evaluate(self, images_root: Path, ann_root: Optional[Path]) -> dict:
        pairs = find_image_and_mask_pairs(images_root, ann_root) if ann_root else []
        image_list: List[Path] = []
        mask_lookup = {}
        missing_masks: List[str] = []
        
        if ann_root:
            for img_path, mpath in pairs:
                if mpath is None or not mpath.exists():
                    missing_masks.append(str(img_path))
                    continue
                image_list.append(img_path)
                mask_lookup[img_path] = mpath
        else:
            # æ”¹è¿›çš„å›¾åƒæ–‡ä»¶æŸ¥æ‰¾é€»è¾‘
            print(f"Searching for images in: {images_root}")
            for dirpath, _, filenames in os.walk(images_root):
                for fname in filenames:
                    if is_image_file(fname):
                        img_path = Path(dirpath) / fname
                        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å¯è¯»
                        if img_path.exists() and img_path.stat().st_size > 0:
                            image_list.append(img_path)
                            if len(image_list) % 100 == 0:
                                print(f"Found {len(image_list)} images so far...")
        
        print(f"Total images found: {len(image_list)}")
        
        if len(image_list) == 0:
            print("No images found! Please check the image directory path.")
            return {"error": "No images found", "summary": {}}

        broken_log = []
        results = []
        total_time = 0.0
        total_detections = 0

        # Positive/Negative accumulators
        pos_dices = []
        pos_ious = []
        pos_precisions = []
        pos_recalls = []
        pos_f1s = []
        pos_tp_sum = 0
        pos_fp_sum = 0
        pos_fn_sum = 0

        neg_images = 0
        neg_tn_images = 0
        neg_fp_images = 0

        print(f"Processing {len(image_list)} images...")
        
        for idx, img_path in enumerate(sorted(image_list)):
            if idx % 10 == 0:
                print(f"Processing {idx+1}/{len(image_list)}: {img_path.name}")
                
            img = try_read_image(img_path)
            if img is None:
                broken_log.append(str(img_path))
                continue

            start = time.time()
            
            # ä»æ ‡æ³¨æ–‡ä»¶è·å–è¾¹ç•Œæ¡†æç¤ºï¼Œå¹¶æ„å»ºGTæ©ç ï¼ˆé€‚é…LDPolypVideo txtï¼‰
            boxes_list = []
            gt_mask_from_boxes = None
            is_negative = False
            if ann_root:
                gt_path = mask_lookup.get(img_path)
                if gt_path and gt_path.exists():
                    if gt_path.suffix.lower() == ".txt":
                        # ä»txtæ–‡ä»¶è¯»å–è¾¹ç•Œæ¡†å’Œé˜´æ€§æ ‡å¿—
                        boxes, is_negative = self._read_boxes_from_txt(gt_path, img.shape)
                        if boxes:
                            boxes_list = boxes
                        # é˜´æ€§æ ·æœ¬ï¼šGTæ©ç å…¨é›¶ï¼›é˜³æ€§æ ·æœ¬ï¼šç”¨æ‰€æœ‰boxesç»˜åˆ¶GTæ©ç 
                        h, w = img.shape[:2]
                        m = np.zeros((h, w), dtype=np.uint8)
                        if not is_negative and boxes:
                            for (x1, y1, x2, y2) in boxes:
                                x1c = max(0, min(w - 1, x1))
                                y1c = max(0, min(h - 1, y1))
                                x2c = max(0, min(w - 1, x2))
                                y2c = max(0, min(h - 1, y2))
                                if x2c > x1c and y2c > y1c:
                                    m[y1c:y2c, x1c:x2c] = 255
                        gt_mask_from_boxes = m
            
            # ä½¿ç”¨è¾¹ç•Œæ¡†æç¤ºè¿›è¡Œé¢„æµ‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if boxes_list:
                pred_mask, detections = self.predict_mask_with_boxes(img, boxes_list)
            else:
                pred_mask, detections = self.predict_mask_with_sam(img)
            
            elapsed = time.time() - start
            total_time += elapsed
            total_detections += detections

            metrics = {}
            if ann_root:
                gt_path = mask_lookup.get(img_path)
                if gt_path and gt_path.exists():
                    # æ ¹æ®æ–‡ä»¶æ‰©å±•ååˆ¤æ–­æ˜¯å›¾åƒè¿˜æ˜¯LDPolypVideoæ ¼å¼çš„txt
                    if gt_path.suffix.lower() in [".png", ".jpg", ".tif", ".tiff", ".bmp"]:
                        gt_mask = cv2.imread(str(gt_path), cv2.IMREAD_GRAYSCALE)
                        if gt_mask is not None:
                            # ç¡®ä¿ground truth maskæ˜¯äºŒå€¼çš„
                            gt_bin = (gt_mask > 128).astype(np.uint8)
                            
                            # å…³é”®ä¿®å¤ï¼šç¡®ä¿é¢„æµ‹æ©ç å’ŒGTæ©ç å…·æœ‰ç›¸åŒçš„å°ºå¯¸
                            gt_h, gt_w = gt_bin.shape
                            pred_h, pred_w = pred_mask.shape
                            
                            # å¦‚æœå°ºå¯¸ä¸åŒ¹é…ï¼Œè°ƒæ•´é¢„æµ‹æ©ç åˆ°GTå°ºå¯¸
                            if pred_h != gt_h or pred_w != gt_w:
                                pred_resized = cv2.resize(pred_mask, (gt_w, gt_h), interpolation=cv2.INTER_NEAREST)
                            else:
                                pred_resized = pred_mask
                            
                            # äºŒå€¼åŒ–é¢„æµ‹æ©ç 
                            pr_bin = (pred_resized > 0).astype(np.uint8)
                            
                            # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºæ©ç å°ºå¯¸
                            if idx < 5:
                                print(f"    Mask sizes: GT={gt_bin.shape}, Pred={pred_mask.shape}, Resized={pred_resized.shape}")
                                print(f"    GT sum: {gt_bin.sum()}, Pred sum: {pr_bin.sum()}")
                            
                            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
                            metrics = self._compute_metrics_numpy(gt_bin, pr_bin)
                            
                            # è°ƒè¯•ä¿¡æ¯
                            if idx < 5:  # åªå¯¹å‰5å¼ å›¾ç‰‡è¾“å‡ºè°ƒè¯•ä¿¡æ¯
                                print(f"  Debug {img_path.name}: GT sum={gt_bin.sum()}, Pred sum={pr_bin.sum()}")
                                print(f"    GT regions: {metrics.get('gt_regions', 0)}, Pred regions: {metrics.get('pred_regions', 0)}")
                                print(f"    TP: {metrics.get('tp', 0)}, FP: {metrics.get('fp', 0)}, FN: {metrics.get('fn', 0)}")
                                print(f"    Dice: {metrics.get('dice', 0):.4f}, IoU: {metrics.get('iou', 0):.4f}")
                                print(f"    Precision: {metrics.get('precision', 0):.4f}, Recall: {metrics.get('recall', 0):.4f}")
                                if 'f1' in metrics:
                                    print(f"    F1: {metrics.get('f1', 0):.4f}")
                        else:
                            broken_log.append(str(gt_path))
                            continue
                    elif gt_path.suffix.lower() == ".txt":
                        # ä»LDPolypVideoçš„txtæ–‡ä»¶åˆ›å»ºæ©ç ï¼ˆæ”¯æŒé˜´æ€§æ ·æœ¬ï¼‰
                        gt_mask = gt_mask_from_boxes
                        if gt_mask is not None:
                            gt_bin = (gt_mask > 0).astype(np.uint8)
                            gt_h, gt_w = gt_bin.shape
                            pred_h, pred_w = pred_mask.shape
                            if pred_h != gt_h or pred_w != gt_w:
                                pred_resized = cv2.resize(pred_mask, (gt_w, gt_h), interpolation=cv2.INTER_NEAREST)
                            else:
                                pred_resized = pred_mask
                            pr_bin = (pred_resized > 0).astype(np.uint8)
                            if idx < 5:
                                print(f"    Mask sizes: GT={gt_bin.shape}, Pred={pred_mask.shape}, Resized={pred_resized.shape}")
                                print(f"    GT sum: {gt_bin.sum()}, Pred sum: {pr_bin.sum()}")
                            # é˜´æ€§æ ·æœ¬ç»Ÿè®¡ç‰¹å¼‚æ€§ï¼›é˜³æ€§æ ·æœ¬æŒ‰è¿é€šåŸŸè®¡ç®—
                            if is_negative:
                                neg_images += 1
                                # é¢„æµ‹æ˜¯å¦æœ‰ä»»ä½•è¿é€šåŸŸ
                                from skimage.measure import label
                                pr_label = label(pr_bin)
                                has_pred_region = pr_label.max() > 0
                                if has_pred_region:
                                    neg_fp_images += 1
                                    metrics = {"specificity": 0.0, "dice": 0.0, "iou": 0.0}
                                else:
                                    neg_tn_images += 1
                                    metrics = {"specificity": 1.0, "dice": 1.0, "iou": 1.0}
                            else:
                                metrics = self._compute_metrics_numpy(gt_bin, pr_bin)
                                # ç´¯è®¡æ­£æ ·æœ¬æŒ‡æ ‡
                                pos_tp_sum += metrics.get("tp", 0)
                                pos_fp_sum += metrics.get("fp", 0)
                                pos_fn_sum += metrics.get("fn", 0)
                                pos_dices.append(metrics.get("dice", 0.0))
                                pos_ious.append(metrics.get("iou", 0.0))
                                pos_precisions.append(metrics.get("precision", 0.0))
                                pos_recalls.append(metrics.get("recall", 0.0))
                                if "f1" in metrics:
                                    pos_f1s.append(metrics.get("f1", 0.0))
                            
                            # è°ƒè¯•ä¿¡æ¯
                            if idx < 5:  # åªå¯¹å‰5å¼ å›¾ç‰‡è¾“å‡ºè°ƒè¯•ä¿¡æ¯
                                print(f"  Debug {img_path.name}: GT sum={gt_bin.sum()}, Pred sum={pr_bin.sum()}")
                                print(f"    GT regions: {metrics.get('gt_regions', 0)}, Pred regions: {metrics.get('pred_regions', 0)}")
                                print(f"    TP: {metrics.get('tp', 0)}, FP: {metrics.get('fp', 0)}, FN: {metrics.get('fn', 0)}")
                                print(f"    Dice: {metrics.get('dice', 0):.4f}, IoU: {metrics.get('iou', 0):.4f}")
                                print(f"    Precision: {metrics.get('precision', 0):.4f}, Recall: {metrics.get('recall', 0):.4f}")
                                if 'f1' in metrics:
                                    print(f"    F1: {metrics.get('f1', 0):.4f}")
                        else:
                            broken_log.append(str(gt_path))
                            continue
                    else:
                        broken_log.append(str(gt_path))
                        continue

            results.append({
                "image": str(img_path.relative_to(images_root)),
                "time_sec": elapsed,
                "detections": detections,
                "metrics": metrics,
            })

        num = len(results)
        if num == 0:
            print("No images were successfully processed!")
            return {"error": "No images processed", "summary": {}}

        avg_time = total_time / num
        fps_avg_latency = 1.0 / avg_time if avg_time > 0 else 0.0
        fps_throughput = num / total_time if total_time > 0 else 0.0

        # è®¡ç®—å¹³å‡æ€§èƒ½æŒ‡æ ‡ï¼ˆåˆ†åˆ«ç»Ÿè®¡é˜³æ€§å’Œé˜´æ€§ï¼Œå†ç»™å‡ºç»¼åˆï¼‰
        metrics_list = [r["metrics"] for r in results if r["metrics"]]
        # mDice/mIoUï¼ˆimage-level mean over all images; negatives counted as 1 when perfectly empty, 0 otherwiseï¼‰
        mdice_vals = [m["dice"] for m in metrics_list if "dice" in m]
        miou_vals = [m["iou"] for m in metrics_list if "iou" in m]
        m_dice = float(np.mean(mdice_vals)) if mdice_vals else 0.0
        m_iou = float(np.mean(miou_vals)) if miou_vals else 0.0
        # æ­£æ ·æœ¬å¹³å‡
        pos_avg = {
            "dice": float(np.mean(pos_dices)) if pos_dices else 0.0,
            "iou": float(np.mean(pos_ious)) if pos_ious else 0.0,
            "precision": float(np.mean(pos_precisions)) if pos_precisions else 0.0,
            "recall": float(np.mean(pos_recalls)) if pos_recalls else 0.0,
            "f1": float(np.mean(pos_f1s)) if pos_f1s else 0.0,
            "tp": int(pos_tp_sum),
            "fp": int(pos_fp_sum),
            "fn": int(pos_fn_sum),
        }
        # é˜´æ€§æ ·æœ¬ç‰¹å¼‚æ€§
        specificity = (neg_tn_images / (neg_tn_images + neg_fp_images)) if (neg_tn_images + neg_fp_images) > 0 else 0.0
        neg_avg = {
            "num_negative_images": int(neg_images),
            "tn_images": int(neg_tn_images),
            "fp_images": int(neg_fp_images),
            "specificity": float(specificity),
        }
        # ç»¼åˆï¼šå¯¹æ­£æ ·æœ¬çš„dice/iou/precision/recall/f1å–å‡å€¼ï¼›æŠ¥å‘Šé˜´æ€§çš„specificity
        avg_dice = pos_avg["dice"]
        avg_iou = pos_avg["iou"]
        avg_precision = pos_avg["precision"]
        avg_recall = pos_avg["recall"]
        avg_f1 = pos_avg["f1"]

        # è®¡ç®—å¹³å‡æ£€æµ‹æ•°é‡
        avg_detections = total_detections / num if num > 0 else 0.0

        summary = {
            "total_images": num,
            "skipped_broken": len(broken_log),
            "total_time_sec": total_time,
            "avg_time_per_image_sec": avg_time,
            "fps_avg_latency": fps_avg_latency,
            "fps_throughput": fps_throughput,
            "total_detections": total_detections,
            "avg_detections": avg_detections,
            "avg_dice": avg_dice,
            "avg_iou": avg_iou,
            "mDice": m_dice,
            "mIoU": m_iou,
            "avg_precision": avg_precision,
            "avg_recall": avg_recall,
            "avg_f1": avg_f1,
            "specificity": float(specificity),
            "positive_metrics": pos_avg,
            "negative_metrics": neg_avg,
        }

        return {
            "summary": summary,
            "results": results,
            "broken_images": broken_log,
            "missing_masks": missing_masks,
        }


def main() -> None:
    import argparse

    parser = argparse.ArgumentParser(description="Evaluate TinySAM on Polys/Test with improved metrics")
    parser.add_argument("--test-images", type=str, required=True, help="Path to Polys/Test/Images directory")
    parser.add_argument("--test-annotations", type=str, required=False, help="Path to Polys/Test/Annotations directory")
    parser.add_argument("--sam-weights", type=str, default="../results_ldpolyvideo/best_model.pth")
    parser.add_argument("--yolo-weights", type=str, default=None, help="Optional YOLO weights for box prompts")
    parser.add_argument("--device", type=str, default=None)
    parser.add_argument("--out", type=str, default="polys_tinysam_eval_report.json")
    parser.add_argument("--broken-log", type=str, default="broken_images.txt")
    parser.add_argument("--yolo-conf", type=float, default=0.25)
    parser.add_argument("--yolo-iou", type=float, default=0.45)
    args = parser.parse_args()

    images_root = Path(args.test_images)
    ann_root = Path(args.test_annotations) if args.test_annotations else None

    if not images_root.exists():
        print(f"Test Images directory not found: {images_root}")
        sys.exit(1)
    if ann_root and not ann_root.exists():
        print(f"Annotations directory not found: {ann_root}")
        sys.exit(1)

    evaluator = TinySAMEvaluator(
        sam_weights=args.sam_weights,
        yolo_weights=args.yolo_weights,
        device=args.device,
        yolo_conf=args.yolo_conf,
        yolo_iou=args.yolo_iou,
    )

    report = evaluator.evaluate(images_root, ann_root)

    # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
    if "error" in report:
        print(f"âŒ Error: {report['error']}")
        if "summary" in report and report["summary"]:
            # å¦‚æœæœ‰summaryï¼Œä»ç„¶å¯ä»¥ä¿å­˜æŠ¥å‘Š
            pass
        else:
            print("No summary available. Exiting.")
            return

    # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    with open(args.out, "w") as f:
        json.dump(report, f, indent=2)

    if report.get("broken_images"):
        with open(args.broken_log, "w") as f:
            for p in report["broken_images"]:
                f.write(p + "\n")

    # æ‰“å°è¯¦ç»†çš„æ€§èƒ½æŠ¥å‘Š
    s = report["summary"]
    print("\n" + "="*70)
    print("ğŸš€ TinySAM Evaluation Report (Polys/Test)")
    print("="*70)
    print(f"ğŸ“Š Images evaluated: {s['total_images']} (skipped broken: {s['skipped_broken']})")
    print(f"â±ï¸  Total time: {s['total_time_sec']:.2f}s | Avg time/img: {s['avg_time_per_image_sec']:.4f}s")
    print(f"ğŸš€ FPS (avg latency): {s['fps_avg_latency']:.2f} | FPS (throughput): {s['fps_throughput']:.2f}")
    print(f"ğŸ“Œ mDice: {s.get('mDice', 0.0):.4f} | mIoU: {s.get('mIoU', 0.0):.4f} | Specificity: {s.get('specificity', 0.0):.4f}")
    print(f"ğŸ¯ Total detections: {s['total_detections']} | Avg detections: {s['avg_detections']:.2f}")
    print(f"ğŸ“ˆ Performance Metrics:")
    print(f"    Dice: {s['avg_dice']:.4f} | IoU: {s['avg_iou']:.4f}")
    print(f"    Precision: {s['avg_precision']:.4f} | Recall: {s['avg_recall']:.4f}")
    print(f"    F1: {s['avg_f1']:.4f}")
    print(f"ğŸ’¾ Report saved to: {args.out}")
    print("="*70)


if __name__ == "__main__":
    main()


