#!/usr/bin/env python3
"""
å¯åŠ¨DINOv2åœ¨Kvasir-SEGæ•°æ®é›†ä¸Šçš„é¢„è®­ç»ƒ
åŸºäºç°æœ‰é…ç½®æ–‡ä»¶å’Œè®­ç»ƒè„šæœ¬çš„å®Œæ•´å¯åŠ¨è„šæœ¬
"""

import os
import sys
import subprocess
import argparse
from pathlib import Path
import yaml
import shutil

def check_environment():
    """æ£€æŸ¥è®­ç»ƒç¯å¢ƒ"""
    print("ğŸ” æ£€æŸ¥è®­ç»ƒç¯å¢ƒ...")
    
    # æ£€æŸ¥CUDA
    if not os.system("nvidia-smi > /dev/null 2>&1") == 0:
        print("âŒ æœªæ£€æµ‹åˆ°CUDAç¯å¢ƒ")
        return False
    
    # æ£€æŸ¥PythonåŒ…
    try:
        import torch
        print(f"âœ… PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"âœ… CUDAå¯ç”¨: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"âœ… GPUæ•°é‡: {torch.cuda.device_count()}")
            for i in range(torch.cuda.device_count()):
                print(f"   GPU {i}: {torch.cuda.get_device_name(i)}")
    except ImportError:
        print("âŒ PyTorchæœªå®‰è£…")
        return False
    
    return True

def check_data_directory(data_path):
    """æ£€æŸ¥æ•°æ®ç›®å½•"""
    print(f"ğŸ” æ£€æŸ¥æ•°æ®ç›®å½•: {data_path}")
    
    if not Path(data_path).exists():
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_path}")
        return False
    
    # ç»Ÿè®¡å›¾åƒæ–‡ä»¶
    image_extensions = ['.jpg', '.jpeg', '.png', '.tif', '.tiff', '.bmp']
    image_count = 0
    
    for ext in image_extensions:
        image_count += len(list(Path(data_path).rglob(f'*{ext}')))
        image_count += len(list(Path(data_path).rglob(f'*{ext.upper()}')))
    
    print(f"âœ… æ‰¾åˆ° {image_count} å¼ å›¾åƒ")
    
    if image_count == 0:
        print("âŒ æ•°æ®ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾åƒæ–‡ä»¶")
        return False
    
    return True

def prepare_config(args):
    """å‡†å¤‡è®­ç»ƒé…ç½®"""
    print("ğŸ“ å‡†å¤‡è®­ç»ƒé…ç½®...")
    
    # åŸºç¡€é…ç½®
    config = {
        'MODEL': {'WEIGHTS': ''},
        'compute_precision': {'grad_scaler': True},
        
        # å­¦ç”Ÿå’Œæ•™å¸ˆæ¨¡å‹é…ç½®
        'student': {
            'arch': args.arch,
            'patch_size': args.patch_size,
            'drop_path_rate': 0.3,
            'layerscale': 1e-5,
            'drop_path_uniform': True,
            'pretrained_weights': '',
            'ffn_layer': 'mlp',
            'block_chunks': 0,
            'qkv_bias': True,
            'proj_bias': True,
            'ffn_bias': True,
            'num_register_tokens': 0,
            'interpolate_antialias': False,
            'interpolate_offset': 0.1
        },
        
        'teacher': {
            'momentum_teacher': 0.996,
            'final_momentum_teacher': 1.0,
            'warmup_teacher_temp': 0.04,
            'teacher_temp': 0.07,
            'warmup_teacher_temp_epochs': 30
        },
        
        # DINOå’ŒiBOTé…ç½®
        'dino': {
            'loss_weight': 1.0,
            'head_n_prototypes': 65536,
            'head_bottleneck_dim': 256,
            'head_nlayers': 3,
            'head_hidden_dim': 2048,
            'koleo_loss_weight': 0.1
        },
        
        'ibot': {
            'loss_weight': 1.0,
            'mask_sample_probability': 0.5,
            'mask_ratio_min_max': [0.1, 0.5],
            'separate_head': False,
            'head_n_prototypes': 65536,
            'head_bottleneck_dim': 256,
            'head_nlayers': 3,
            'head_hidden_dim': 2048
        },
        
        # è®­ç»ƒé…ç½®
        'train': {
            'batch_size_per_gpu': args.batch_size,
            'dataset_path': f'ImageNet:root={args.data_path}:split=TRAIN:extra=',
            'output_dir': args.output_dir,
            'saveckp_freq': 20,
            'seed': 0,
            'num_workers': args.num_workers,
            'OFFICIAL_EPOCH_LENGTH': args.epoch_length,
            'cache_dataset': True,
            'centering': 'centering'
        },
        
        # ä¼˜åŒ–å™¨é…ç½®
        'optim': {
            'epochs': args.epochs,
            'weight_decay': 0.08,
            'weight_decay_end': 0.4,
            'base_lr': args.lr,
            'warmup_epochs': 20,
            'min_lr': 1e-6,
            'clip_grad': 1.0,
            'freeze_last_layer_epochs': 1,
            'scaling_rule': 'sqrt_wrt_1024',
            'patch_embed_lr_mult': 0.2,
            'layerwise_decay': 0.9,
            'adamw_beta1': 0.9,
            'adamw_beta2': 0.999,
            'batch_size_per_gpu': args.batch_size
        },
        
        # è£å‰ªé…ç½®
        'crops': {
            'global_crops_scale': [0.32, 1.0],
            'local_crops_number': 2,
            'local_crops_scale': [0.05, 0.32],
            'global_crops_size': args.img_size,
            'local_crops_size': args.img_size // 2
        },
        
        # è¯„ä¼°é…ç½®
        'evaluation': {
            'eval_period_iterations': 12500
        },
        
        # æ¨¡å‹é…ç½®
        'model': {
            'arch': args.arch
        }
    }
    
    # ä¿å­˜é…ç½®æ–‡ä»¶
    config_path = Path(args.output_dir) / 'training_config.yaml'
    config_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(config_path, 'w') as f:
        yaml.dump(config, f, default_flow_style=False)
    
    print(f"âœ… é…ç½®æ–‡ä»¶å·²ä¿å­˜: {config_path}")
    return config_path

def launch_training(config_path, args):
    """å¯åŠ¨åˆ†å¸ƒå¼è®­ç»ƒ"""
    print("ğŸš€ å¯åŠ¨DINOv2è®­ç»ƒ...")
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    env = os.environ.copy()
    env['PYTHONPATH'] = str(Path.cwd() / 'dinov2')
    env['CUDA_VISIBLE_DEVICES'] = args.gpu_ids
    
    # æ„å»ºè®­ç»ƒå‘½ä»¤
    if args.distributed and args.num_gpus > 1:
        # åˆ†å¸ƒå¼è®­ç»ƒ
        cmd = [
            'torchrun',
            f'--nproc_per_node={args.num_gpus}',
            '--master_port=29500',
            'dinov2/dinov2/train/train.py',
            f'--config-file={config_path}',
            f'train.output_dir={args.output_dir}',
            f'optim.epochs={args.epochs}',
            f'optim.batch_size_per_gpu={args.batch_size}',
            f'model.arch={args.arch}',
            f'student.arch={args.arch}'
        ]
        
        if args.disable_xformers:
            cmd.append('--disable_xformers')
            
    else:
        # å•GPUè®­ç»ƒ
        cmd = [
            sys.executable,
            'dinov2/dinov2/train/train.py',
            f'--config-file={config_path}',
            f'train.output_dir={args.output_dir}',
            f'optim.epochs={args.epochs}',
            f'optim.batch_size_per_gpu={args.batch_size}',
            f'model.arch={args.arch}',
            f'student.arch={args.arch}'
        ]
        
        if args.disable_xformers:
            cmd.append('--disable_xformers')
    
    print(f"ğŸ”§ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"ğŸ“Š è®­ç»ƒé…ç½®:")
    print(f"   - æ¨¡å‹æ¶æ„: {args.arch}")
    print(f"   - è®­ç»ƒè½®æ•°: {args.epochs}")
    print(f"   - æ‰¹å¤§å°: {args.batch_size}")
    print(f"   - å­¦ä¹ ç‡: {args.lr}")
    print(f"   - GPUæ•°é‡: {args.num_gpus}")
    print(f"   - æ•°æ®è·¯å¾„: {args.data_path}")
    
    try:
        # å¯åŠ¨è®­ç»ƒ
        process = subprocess.Popen(
            cmd,
            env=env,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            bufsize=1
        )
        
        # å®æ—¶è¾“å‡ºæ—¥å¿—
        log_file = Path(args.output_dir) / 'training.log'
        with open(log_file, 'w') as f:
            for line in process.stdout:
                print(line.strip())
                f.write(line)
                f.flush()
        
        # ç­‰å¾…è®­ç»ƒå®Œæˆ
        return_code = process.wait()
        
        if return_code == 0:
            print("ğŸ‰ è®­ç»ƒæˆåŠŸå®Œæˆï¼")
            print(f"ğŸ“ æ¨¡å‹æƒé‡ä¿å­˜åœ¨: {args.output_dir}")
            return True
        else:
            print(f"âŒ è®­ç»ƒå¤±è´¥ï¼Œè¿”å›ç : {return_code}")
            return False
            
    except KeyboardInterrupt:
        print("\nâš ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        if process:
            process.terminate()
        return False
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¯åŠ¨å¤±è´¥: {e}")
        return False

def main():
    parser = argparse.ArgumentParser(description='å¯åŠ¨DINOv2åœ¨Kvasir-SEGæ•°æ®é›†ä¸Šçš„é¢„è®­ç»ƒ')
    
    # æ•°æ®é…ç½®
    parser.add_argument('--data_path', type=str, 
                       default='/home/huangmanling/TinySAM-main/Kvasir-SEG/dummy',
                       help='Kvasir-SEGæ•°æ®é›†è·¯å¾„')
    parser.add_argument('--output_dir', type=str,
                       default='./dinov2_kvasir_output',
                       help='è¾“å‡ºç›®å½•')
    
    # æ¨¡å‹é…ç½®
    parser.add_argument('--arch', type=str, default='vit_small',
                       choices=['vit_small', 'vit_base', 'vit_large'],
                       help='æ¨¡å‹æ¶æ„')
    parser.add_argument('--patch_size', type=int, default=16,
                       help='Patchå¤§å°')
    parser.add_argument('--img_size', type=int, default=224,
                       help='è¾“å…¥å›¾åƒå°ºå¯¸')
    
    # è®­ç»ƒé…ç½®
    parser.add_argument('--epochs', type=int, default=100,
                       help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch_size', type=int, default=8,
                       help='æ¯GPUæ‰¹å¤§å°')
    parser.add_argument('--lr', type=float, default=3e-4,
                       help='å­¦ä¹ ç‡')
    parser.add_argument('--epoch_length', type=int, default=1250,
                       help='æ¯ä¸ªepochçš„è¿­ä»£æ¬¡æ•°')
    
    # ç¡¬ä»¶é…ç½®
    parser.add_argument('--num_gpus', type=int, default=1,
                       help='ä½¿ç”¨çš„GPUæ•°é‡')
    parser.add_argument('--gpu_ids', type=str, default='1',
                       help='GPU IDï¼Œç”¨é€—å·åˆ†éš”')
    parser.add_argument('--num_workers', type=int, default=8,
                       help='æ•°æ®åŠ è½½çº¿ç¨‹æ•°')
    parser.add_argument('--distributed', action='store_true',
                       help='æ˜¯å¦ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒ')
    parser.add_argument('--disable_xformers', action='store_true',
                       help='ç¦ç”¨xformersä¼˜åŒ–')
    
    # å…¶ä»–é€‰é¡¹
    parser.add_argument('--resume', type=str, default=None,
                       help='æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„')
    parser.add_argument('--dry_run', action='store_true',
                       help='åªæ£€æŸ¥ç¯å¢ƒï¼Œä¸å¯åŠ¨è®­ç»ƒ')
    
    args = parser.parse_args()
    
    print("ğŸ¯ DINOv2 Kvasir-SEG é¢„è®­ç»ƒå¯åŠ¨å™¨")
    print("=" * 50)
    
    # æ£€æŸ¥ç¯å¢ƒ
    if not check_environment():
        print("âŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥")
        return False
    
    # æ£€æŸ¥æ•°æ®
    if not check_data_directory(args.data_path):
        print("âŒ æ•°æ®æ£€æŸ¥å¤±è´¥")
        return False
    
    # å¦‚æœæ˜¯å¹²è¿è¡Œï¼Œç›´æ¥é€€å‡º
    if args.dry_run:
        print("âœ… ç¯å¢ƒæ£€æŸ¥å®Œæˆï¼ˆå¹²è¿è¡Œæ¨¡å¼ï¼‰")
        return True
    
    # å‡†å¤‡é…ç½®
    config_path = prepare_config(args)
    
    # å¯åŠ¨è®­ç»ƒ
    success = launch_training(config_path, args)
    
    if success:
        print("\nğŸ‰ è®­ç»ƒä»»åŠ¡å®Œæˆï¼")
        print(f"ğŸ“ æ£€æŸ¥è¾“å‡ºç›®å½•: {args.output_dir}")
        print("ğŸ’¡ åç»­æ­¥éª¤:")
        print("   1. éªŒè¯ç”Ÿæˆçš„æƒé‡æ–‡ä»¶")
        print("   2. è¿è¡Œè¯„ä¼°è„šæœ¬")
        print("   3. å°†æƒé‡ç”¨äºYOLOæ£€æµ‹ä»»åŠ¡")
    else:
        print("\nâŒ è®­ç»ƒä»»åŠ¡å¤±è´¥")
        print("ğŸ’¡ æ•…éšœæ’é™¤:")
        print("   1. æ£€æŸ¥GPUå†…å­˜æ˜¯å¦å……è¶³")
        print("   2. æ£€æŸ¥æ•°æ®è·¯å¾„æ˜¯å¦æ­£ç¡®")
        print("   3. æŸ¥çœ‹è®­ç»ƒæ—¥å¿—è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯")
    
    return success

if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)